{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Calculate image height and width\n",
    "h = image.shape[0]\n",
    "w = image.shape[1]\n",
    "\n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    (assuming your grayscaled image is called 'gray')\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Or use BGR2GRAY if you read an image with cv2.imread()\n",
    "    # return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def draw_lines_part1(img, lines, color=[255, 0, 0], thickness=2):\n",
    "    \"\"\"\n",
    "    NOTE: this is the function you might want to use as a starting point once you want to \n",
    "    average/extrapolate the line segments you detect to map out the full\n",
    "    extent of the lane (going from the result shown in raw-lines-example.mp4\n",
    "    to that shown in P1_example.mp4).  \n",
    "    \n",
    "    Think about things like separating line segments by their \n",
    "    slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n",
    "    line vs. the right line.  Then, you can average the position of each of \n",
    "    the lines and extrapolate to the top and bottom of the lane.\n",
    "    \n",
    "    This function draws `lines` with `color` and `thickness`.    \n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    "    If you want to make the lines semi-transparent, think about combining\n",
    "    this function with the weighted_img() function below\n",
    "    \"\"\"    \n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "                 \n",
    "\n",
    "def draw_lines_part2(img, lines, color=[255, 0, 0], thickness=10):\n",
    "    \"\"\"\n",
    "    NOTE: this is the function you might want to use as a starting point once you want to \n",
    "    average/extrapolate the line segments you detect to map out the full\n",
    "    extent of the lane (going from the result shown in raw-lines-example.mp4\n",
    "    to that shown in P1_example.mp4).  \n",
    "    \n",
    "    Think about things like separating line segments by their \n",
    "    slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n",
    "    line vs. the right line.  Then, you can average the position of each of \n",
    "    the lines and extrapolate to the top and bottom of the lane.\n",
    "    \n",
    "    This function draws `lines` with `color` and `thickness`.    \n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    "    If you want to make the lines semi-transparent, think about combining\n",
    "    this function with the weighted_img() function below\n",
    "    \"\"\"\n",
    "    # Making left/right x and y lists global.\n",
    "    global x_p_l \n",
    "    global y_p_l\n",
    "    global x_p_r \n",
    "    global y_p_r\n",
    "    \n",
    "    # Initializing the lists as empty.\n",
    "    x_p_l = []\n",
    "    y_p_l = []\n",
    "    x_p_r = []\n",
    "    y_p_r = []\n",
    "    slope_l = []\n",
    "    slope_r = []\n",
    "    \n",
    "    # Sorting points into left x and y OR right x and y lists, \n",
    "    # based on slope range.\n",
    "    \n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            slope = ((y2-y1)/(x2-x1))\n",
    "            if not np.isnan(slope) or np.isinf(slope) or (slope == 0):\n",
    "                if slope < -0.6 and slope > -1:\n",
    "                    x_p_l += [x1, x2]\n",
    "                    y_p_l += [y1, y2]\n",
    "                    slope_l += [slope]\n",
    "                elif slope > 0.2 and slope < 1.5:\n",
    "                    x_p_r += [x1, x2]\n",
    "                    y_p_r += [y1, y2]\n",
    "                    slope_r += [slope]\n",
    "    \n",
    "    # Average out the x and y points, and calculate the mean slopes.\n",
    "    avg_x_l = np.mean(x_p_l, dtype=np.float32)\n",
    "    avg_x_r = np.mean(x_p_r, dtype=np.float32)\n",
    "    avg_y_l = np.mean(y_p_l, dtype=np.float32)\n",
    "    avg_y_r = np.mean(y_p_r, dtype=np.float32)\n",
    "    avg_slope_l = np.mean(slope_l, dtype=np.float32)\n",
    "    avg_slope_r = np.mean(slope_r, dtype=np.float32)\n",
    "    \n",
    "    # Calculate intercepts from the means above\n",
    "    # b = y - mx\n",
    "    b_l = avg_y_l - (avg_slope_l * avg_x_l)\n",
    "    b_r = avg_y_r - (avg_slope_r * avg_x_r)\n",
    "    \n",
    "    # Calculate X coordinates of the lines to be drawn\n",
    "    # using information above. The Y values are the \n",
    "    # y coordinates of the bounding box/mask as defined\n",
    "    # in the pipeline further below.\n",
    "    y_max = max(y_p_l) #y_mask[0]\n",
    "    y_min = max(y_p_r) #y_mask[1]\n",
    "    \n",
    "    # X = (Y - b) / m\n",
    "    X_l_lo = (y_max - b_l) / avg_slope_l\n",
    "    X_l_hi = (y_min - b_l) / avg_slope_l\n",
    "    \n",
    "    X_r_lo = (y_max - b_r) / avg_slope_r\n",
    "    X_r_hi = (y_min - b_r) / avg_slope_r\n",
    "    \n",
    "    # Draw lines on the left side and the right side of the image\n",
    "    # using cv2.line() function, and (X,Y) calculated above as points. \n",
    "    img_l = cv2.line(img, (int(X_l_lo), y_max), (int(X_l_hi), y_min), color, thickness)\n",
    "    cv2.line(img_l, (int(X_r_lo), y_max), (int(X_r_hi), y_min), color, thickness)\n",
    "        \n",
    "            \n",
    "    \n",
    "        \n",
    "def hough_lines_p1(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines_part1(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "def hough_lines_p2(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines_part2(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "# Python 3 has support for cool math symbols.\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "\n",
    "def draw_roi(img):\n",
    "    \"\"\"\n",
    "    `img` is the output of the weighted_img(), an image with lines drawn on it.\n",
    "    \n",
    "    The resultant image has ROI drawn on it using cv2.polylines().\n",
    "    \n",
    "    \"\"\"\n",
    "    pts = np.array([[(w//10 + 4,h),((w//2 - 60), (h//2) + 60), \\\n",
    "                        ((w//2 + 80), (h//2) + 60), (w - 20,h)]], dtype=np.int32)\n",
    "    cv2.polylines(img, pts, False, [0,0,255], thickness=4)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-7915e385d3ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mim_copy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_read\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mhu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim_copy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_RGB2HSV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "# TODO: Build your pipeline that will draw lane lines on the test_images\n",
    "# then save them to the test_images directory.\n",
    "\n",
    "############################## Pipeline ############################\n",
    "\n",
    "for i in range(85, 95, 1):\n",
    "    \n",
    "    image_read = mpimg.imread('test_video_frames_challenge/frame{}.jpg'.format(i))\n",
    "    \n",
    "    # Make a copy\n",
    "    im_copy = np.copy(image_read)\n",
    "    \n",
    "    h1,s1,v = cv2.cvtColor(im_copy, cv2.COLOR_RGB2HSV)\n",
    "    plt.imshow(v)\n",
    "    plt.show()\n",
    "    \n",
    "    h2,l,s2 = cv2.cvtColor(im_copy, cv2.COLOR_RGB2HLS)\n",
    "    plt.imshow(hls_im)\n",
    "    plt.show()\n",
    "\n",
    "    # Step 1: Convert to grayscale.  \n",
    "    # Use 'im_copy' as input; use cmap='gray' to see the returned image as grayscale.\n",
    "    # Save result to 'gray'.\n",
    "    gray = grayscale(im_copy)\n",
    "    # display the grayscale image here:\n",
    "    plt.imshow(gray, cmap='gray') and plt.xlabel('Grayscaled image') and plt.show()\n",
    "\n",
    "    # Step 2: Apply Gaussian smoothing/blurring \n",
    "    # Use 'gray' as input; use a 5x5 kernel.\n",
    "    # Save result to 'blur_gray'.\n",
    "    blur_gray = gaussian_blur(gray, 5)\n",
    "\n",
    "    # Step 3: Run Canny edge detection \n",
    "    # Use 'blur_gray' as input; specify low_threshold and high_threshold values.\n",
    "    # Save result to 'edges'.\n",
    "    edges = canny(blur_gray, 80, 200)\n",
    "    # display the image\n",
    "    plt.imshow(edges, cmap='Greys_r') and plt.xlabel('Canny edge detected image') and plt.show()\n",
    "    # Save the edge map in 'test_images_canny_output/'\n",
    "    #mpimg.imsave('test_video_frames_solidYellowLeft/canny.jpg', comb_edges)\n",
    "    # Stack the 'edges' to make it a 3-channel image,\n",
    "    # and save the result to 'comb_edges'.\n",
    "    comb_edges = np.dstack((edges, edges, edges))\n",
    "\n",
    "    # Step 4: Apply Region Masking\n",
    "    # Use 'edges' as input; define the vertices and call the function 'region_of_interest()'.\n",
    "    # Save result to 'masked_edges'.\n",
    " \n",
    "    height = im_copy.shape[0]\n",
    "    width = im_copy.shape[1]\n",
    "    v_poly = np.array([[(width//10 + 4,height),((width//2 - 60), (height//2) + 60), \\\n",
    "                        ((width//2 + 80), (height//2) + 60), (width - 20,height)]], dtype=np.int32)\n",
    "    masked_edges = region_of_interest(edges, vertices=v_poly)\n",
    "    \n",
    "    # Save the masked_edges image in 'test_images_masked_output/'\n",
    "    #mpimg.imsave('test_images_masked_output/masked_edges.jpg', comb_masked_edges)\n",
    "    # Stack the 'masked_edges' to make it a 3-channel image,\n",
    "    # and save the result to 'comb_masked_edges'.\n",
    "    comb_masked_edges = np.dstack((masked_edges, masked_edges, masked_edges))\n",
    "    \n",
    "    # Make the x_mask,y_mask global.\n",
    "    global x_mask\n",
    "    global y_mask \n",
    "    \n",
    "    # Define x_mask,y_mask as the coordinates of the vertices of the polygon ROI.    \n",
    "    x_mask = [v_poly[0][0][0], v_poly[0][1][0], v_poly[0][2][0], v_poly[0][3][0], v_poly[0][0][0]]\n",
    "    y_mask = [v_poly[0][0][1], v_poly[0][1][1], v_poly[0][2][1], v_poly[0][3][1], v_poly[0][0][1]]\n",
    "    \n",
    "    # Step 5: Run Hough Transform\n",
    "    # Use 'masked_edges' as input; pass in suitable values to rho, theta etc.\n",
    "    # Save result to 'hough_image'.\n",
    "    # This uses the updated draw_lines() function. \n",
    "    hough_image = hough_lines_p2(masked_edges, rho=2, theta=np.pi/360, threshold=40, min_line_len=10, max_line_gap=20)\n",
    "    # Save hough_image to a folder. \n",
    "    #mpimg.imsave('test_images_hough_output/hough.jpg', hough_image)  \n",
    "    \n",
    "    # Display the region mask on the original image\n",
    "    # and plot the points on lines detected by hough transform\n",
    "    plt.imshow(im_copy)    \n",
    "    plt.plot(x_mask, y_mask, 'b', lw=4)   \n",
    "    plt.plot(x_p_l, y_p_l, 'ro') and plt.plot(x_p_r, y_p_r, 'ro') and plt.show()\n",
    "\n",
    "    # Step 6: Draw the hough lines on the original image\n",
    "    # Call weighted_img() with 'hough_image' and 'im_copy' as arguments.\n",
    "    # Save result to 'lines_image'\n",
    "    lines_image = weighted_img(hough_image, im_copy)\n",
    "    #draw_roi(lines_image)\n",
    "\n",
    "    # Display the final result (Hough lines on the original image)\n",
    "    plt.imshow(lines_image) and plt.xlabel('Hough lines on the original image') and plt.show()\n",
    "\n",
    "    # Save the images to test_images_output/\n",
    "    #mpimg.imsave('test_images_output/result.jpg', lines_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
